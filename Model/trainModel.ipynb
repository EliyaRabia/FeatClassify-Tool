{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (1000, 86)\n",
      "Fitting 3 folds for each of 256 candidates, totalling 768 fits\n",
      "Best Params: {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.9090909090909091\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.89      0.89      0.89        22\n",
      "weighted avg       0.91      0.91      0.91        22\n",
      "\n",
      "Model saved to my_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, ks_2samp, chisquare\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import joblib  # or pickle, according to preference\n",
    "\n",
    "# 1) Reading your files\n",
    "file_path1 = 'modelData/melb_data.csv'\n",
    "file_path2 = 'modelData/Obesity prediction.csv'\n",
    "file_path3 = 'modelData/Titanic.csv'\n",
    "file_path4 = 'modelData/phone_usage_india.csv'\n",
    "file_path5 = 'modelData/panic_attack_dataset.csv'\n",
    "\n",
    "data1 = pd.read_csv(file_path1)\n",
    "data2 = pd.read_csv(file_path2)\n",
    "data3 = pd.read_csv(file_path3)\n",
    "data4 = pd.read_csv(file_path4)\n",
    "data5 = pd.read_csv(file_path5)\n",
    "\n",
    "# 2) Renaming conflicting column names (as you did in your code)\n",
    "data2 = data2.rename(columns={\n",
    "    'Gender': 'Obesity_prediction_gender',\n",
    "    'Age': 'Obesity_prediction_age'\n",
    "})\n",
    "data3 = data3.rename(columns={\n",
    "    'Age': 'Titanic_age'\n",
    "})\n",
    "data4 = data4.rename(columns={\n",
    "    'Gender': 'Phone_usage_india_gender',\n",
    "    'Age': 'Phone_usage_india_age'\n",
    "})\n",
    "data5 = data5.rename(columns={\n",
    "    'Gender': 'Panic_attack_gender',\n",
    "    'Age': 'Panic_attack_age'\n",
    "})\n",
    "\n",
    "# 3) Combining all DataFrames\n",
    "combined_data = pd.concat(\n",
    "    [data1, data2, data3, data4, data5],\n",
    "    axis=1,\n",
    "    join='inner'\n",
    ")\n",
    "\n",
    "print(\"Combined data shape:\", combined_data.shape)\n",
    "\n",
    "# 4) Defining a list of categorical columns (for labeling is_categorical)\n",
    "categorical_features = [\n",
    "    'Bedroom2', 'Bathroom', 'Car', 'Postcode', 'Distance',\n",
    "    'BuildingArea', 'YearBuilt', 'Price', 'Landsize', 'NCP', 'CH2O',\n",
    "    'FCVC', 'FAF', 'TUE', 'Pclass', 'SibSp', 'Parch', 'Survived',\n",
    "    'Caffeine_Intake', 'Exercise_Frequency', 'Alcohol_Consumption',\n",
    "    'Panic_Score', 'Suburb', 'Type', 'Method', 'SellerG', 'Date',\n",
    "    'CouncilArea', 'Regionname', 'Obesity_prediction_gender', 'family_history', 'FAVC',\n",
    "    'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS', 'Obesity', 'Sex',\n",
    "    'Embarked', 'Phone_usage_india_gender', 'Location', 'Phone Brand', 'OS',\n",
    "    'Primary Use', 'Panic_attack_gender', 'Trigger', 'Sweating',\n",
    "    'Shortness_of_Breath', 'Dizziness', 'Chest_Pain', 'Trembling',\n",
    "    'Medical_History', 'Medication', 'Smoking', 'Therapy'\n",
    "]\n",
    "\n",
    "# 5) Function to prepare the DataFrame for the model (creating target column is_categorical)\n",
    "def prepare_combined_dataset_with_target(df, cat_cols):\n",
    "    df_copy = df.copy()\n",
    "    feature_data = []\n",
    "\n",
    "    for col in df_copy.columns:\n",
    "        # 1 = categorical if in cat_cols, else 0\n",
    "        is_categorical = 1 if col in cat_cols else 0\n",
    "\n",
    "        col_data = df_copy[col]\n",
    "        if pd.api.types.is_numeric_dtype(col_data):\n",
    "            # Numeric values\n",
    "            col_data_dropna = col_data.dropna()\n",
    "            n_total = len(col_data_dropna)\n",
    "            value_counts = col_data_dropna.value_counts()\n",
    "            n_unique = len(value_counts)\n",
    "            unique_ratio = (n_unique / n_total) * 100 if n_total > 0 else 0\n",
    "            max_count = value_counts.max() if len(value_counts) > 0 else 0\n",
    "\n",
    "            if n_total > 1:\n",
    "                column_skewness = skew(col_data_dropna)\n",
    "                column_kurtosis = kurtosis(col_data_dropna)\n",
    "            else:\n",
    "                column_skewness = 0\n",
    "                column_kurtosis = 0\n",
    "\n",
    "            ks_p_value = 0\n",
    "            chi_p_value = 0\n",
    "            if n_total > 1:\n",
    "                # KS\n",
    "                _, ks_p_value = ks_2samp(col_data_dropna, np.random.uniform(size=n_total))\n",
    "\n",
    "                # chi-square with bins\n",
    "                binned_series = pd.cut(col_data_dropna, bins=10, labels=False)\n",
    "                observed = binned_series.value_counts()\n",
    "                expected = np.ones_like(observed) * observed.sum() / len(observed)\n",
    "                _, chi_p_value = chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "        else:\n",
    "            # Textual/categorical values\n",
    "            col_factor, _ = pd.factorize(col_data)\n",
    "            col_factor = pd.Series(col_factor).replace(-1, np.nan).dropna()\n",
    "            n_total = len(col_factor)\n",
    "            value_counts = col_factor.value_counts()\n",
    "            n_unique = len(value_counts)\n",
    "            unique_ratio = (n_unique / n_total) * 100 if n_total > 0 else 0\n",
    "            max_count = value_counts.max() if len(value_counts) > 0 else 0\n",
    "\n",
    "            if n_total > 1:\n",
    "                column_skewness = skew(col_factor)\n",
    "                column_kurtosis = kurtosis(col_factor)\n",
    "            else:\n",
    "                column_skewness = 0\n",
    "                column_kurtosis = 0\n",
    "\n",
    "            ks_p_value = 0\n",
    "            chi_p_value = 0\n",
    "            if n_total > 1:\n",
    "                # KS\n",
    "                _, ks_p_value = ks_2samp(col_factor, np.random.uniform(size=n_total))\n",
    "\n",
    "                # chi-square\n",
    "                observed = value_counts\n",
    "                expected = np.ones_like(observed) * observed.sum() / len(observed)\n",
    "                _, chi_p_value = chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "        feature_data.append({\n",
    "            'skewness': column_skewness,\n",
    "            'kurtosis': column_kurtosis,\n",
    "            'relative_unique_ratio': unique_ratio,\n",
    "            'max_repeated_value_count': max_count,\n",
    "            'ks_p_value': ks_p_value,\n",
    "            'chi_p_value': chi_p_value,\n",
    "            'is_categorical': is_categorical\n",
    "        })\n",
    "    return pd.DataFrame(feature_data)\n",
    "\n",
    "# 6) Preparing the data for the model\n",
    "prepared_data = prepare_combined_dataset_with_target(combined_data, categorical_features)\n",
    "\n",
    "# 7) Separating X, y\n",
    "X = prepared_data.drop(columns=['is_categorical'])\n",
    "Y = prepared_data['is_categorical']\n",
    "\n",
    "# 8) Splitting into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# 9) Defining param_grid for RandomForest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 7, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_rf,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# 10) Testing on the test set\n",
    "test_preds = best_rf_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, test_preds)\n",
    "print(\"Best Params:\", rf_grid_search.best_params_)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, test_preds))\n",
    "\n",
    "# 11) Saving the trained model to a file (e.g., my_model.pkl)\n",
    "model_filename = \"my_model.pkl\"\n",
    "joblib.dump(best_rf_model, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
